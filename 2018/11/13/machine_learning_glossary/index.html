<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="theme-color" content="#123456"><meta name="generator" content="Hexo 4.2.0"><title>机器学习术语表 - Laugh&#039;s blog</title><link rel="manifest" href="/blog/manifest.json"><meta name="application-name" content="Laugh&#039;s blog"><meta name="msapplication-TileImage" content="https://avatars2.githubusercontent.com/u/38065710?s=400&amp;u=b32cf1cc11129ac10e78dd72a9e3dba0aa0d58bd&amp;v=4"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Laugh&#039;s blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta description="本术语表中列出了一般的机器学习术语和 TensorFlow 专用术语的定义。 提示：你可以通过中文名称拼音首字母快速检索。"><meta property="og:type" content="blog"><meta property="og:title" content="机器学习术语表"><meta property="og:url" content="http://www.laugh12321.cn/blog/2018/11/13/machine_learning_glossary/"><meta property="og:site_name" content="Laugh&#039;s blog"><meta property="og:description" content="本术语表中列出了一般的机器学习术语和 TensorFlow 专用术语的定义。 提示：你可以通过中文名称拼音首字母快速检索。"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://laugh12321-1258080753.cos.ap-chengdu.myqcloud.com/laugh&#039;s%20blog/images/photo/Isles%20of%20Scilly%2C%20United%20Kingdom.jpg"><meta property="article:published_time" content="2018-11-13T00:00:00.000Z"><meta property="article:modified_time" content="2020-10-23T08:19:26.211Z"><meta property="article:author" content="Laugh"><meta property="article:tag" content="Machine Learning"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://laugh12321-1258080753.cos.ap-chengdu.myqcloud.com/laugh&#039;s%20blog/images/photo/Isles%20of%20Scilly%2C%20United%20Kingdom.jpg"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://www.laugh12321.cn/blog"},"headline":"Laugh's blog","image":[],"datePublished":"2018-11-13T00:00:00.000Z","dateModified":"2020-10-23T08:19:26.211Z","author":{"@type":"Person","name":"laugh12321"},"description":"本术语表中列出了一般的机器学习术语和 TensorFlow 专用术语的定义。 提示：你可以通过中文名称拼音首字母快速检索。"}</script><link rel="canonical" href="http://www.laugh12321.cn/blog/2018/11/13/machine_learning_glossary/"><link rel="icon" href="https://avatars2.githubusercontent.com/u/38065710?s=400&amp;u=b32cf1cc11129ac10e78dd72a9e3dba0aa0d58bd&amp;v=4"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/font-awesome/5.12.0/css/all.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/highlight.js/9.12.0/styles/atom-one-light.min.css"><link rel="stylesheet" href="https://fonts.loli.net/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/blog/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/cookieconsent/3.1.1/cookieconsent.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/lightgallery/1.6.8/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/justifiedGallery/3.7.0/css/justifiedGallery.min.css"><script src="https://www.googletagmanager.com/gtag/js?id=UA-180999768-1" async></script><script>window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
    
        gtag('config', 'UA-180999768-1');</script><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/outdated-browser/1.1.5/outdatedbrowser.min.css"><script src="https://cdnjs.loli.net/ajax/libs/pace/1.0.2/pace.min.js"></script><!--!--><!--!--><link rel="alternate" href="/blog/atom.xml" title="Laugh's blog" type="application/atom+xml">
</head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/blog/">Laugh</a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/blog/">首页</a><a class="navbar-item" href="/blog/archives">归档</a><a class="navbar-item" href="/blog/categories">分类</a><a class="navbar-item" href="/blog/tags">标签</a><a class="navbar-item" href="/blog/about">关于</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="GitHub" href="https://github.com/laugh12321"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="目录" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><div class="card-image"><span class="image is-7by3"><img class="fill" src="https://laugh12321-1258080753.cos.ap-chengdu.myqcloud.com/laugh&#039;s%20blog/images/photo/Isles%20of%20Scilly%2C%20United%20Kingdom.jpg" alt="机器学习术语表"></span></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2018-11-13T00:00:00.000Z" title="2018-11-13T00:00:00.000Z">2018-11-13</time>发表</span><span class="level-item"><time dateTime="2020-10-23T08:19:26.211Z" title="2020-10-23T08:19:26.211Z">2020-10-23</time>更新</span><span class="level-item"><a class="link-muted" href="/blog/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span><span class="level-item">32 分钟读完 (大约4869个字)</span></div></div><h1 class="title is-3 is-size-4-mobile">机器学习术语表</h1><div class="content"><p>本术语表中列出了一般的机器学习术语和 TensorFlow 专用术语的定义。</p>
<div style="color: #999;font-size: 12px;font-style: italic;">提示：你可以通过中文名称拼音首字母快速检索。</div>

<a id="more"></a>

<h2 id="C"><a href="#C" class="headerlink" title="C"></a>C</h2><h3 id="超参数｜Hyperparameter"><a href="#超参数｜Hyperparameter" class="headerlink" title="超参数｜Hyperparameter"></a>超参数｜Hyperparameter</h3><p>在机器学习中，超参数是在开始学习过程之前设置值的参数，而不是通过训练得到的参数数据。通常情况下，需要对超参数进行优化，给模型选择一组最优超参数，以提高学习的性能和效果。</p>
<h3 id="超平面｜Hyperplane"><a href="#超平面｜Hyperplane" class="headerlink" title="超平面｜Hyperplane"></a>超平面｜Hyperplane</h3><p>将一个空间划分为两个子空间的边界。例如，在二维空间中，直线就是一个超平面，在三维空间中，平面则是一个超平面。在机器学习中更典型的是：超平面是分隔高维度空间的边界。核支持向量机利用超平面将正类别和负类别区分开来（通常是在极高维度空间中）。</p>
<p><img src="https://laugh12321-1258080753.cos.ap-chengdu.myqcloud.com/laugh's%20blog/images/mlg_01.png"></p>
<hr>
<h3 id="参数｜Parameter"><a href="#参数｜Parameter" class="headerlink" title="参数｜Parameter"></a>参数｜Parameter</h3><p>机器学习系统自行训练的模型的变量。</p>
<p>例如，权重就是一种参数，它们的值是机器学习系统通过连续的训练迭代逐渐学习到的。参数的概念与超参数相对应。</p>
<h3 id="测试集｜Test-Set"><a href="#测试集｜Test-Set" class="headerlink" title="测试集｜Test Set"></a>测试集｜Test Set</h3><p>数据集的子集，用于在模型经过验证集验证之后测试模型。当然，有时候我们不设置验证集（主要用于模型调参），直接使用训练数据训练模型后就进行测试。</p>
<h2 id="D"><a href="#D" class="headerlink" title="D"></a>D</h2><hr>
<h3 id="独热编码｜One-Hot-Encoding"><a href="#独热编码｜One-Hot-Encoding" class="headerlink" title="独热编码｜One-Hot Encoding"></a>独热编码｜One-Hot Encoding</h3><p>一种稀疏向量，其中：</p>
<ul>
<li>一个元素设为 1。</li>
<li>所有其他元素均设为 0。</li>
</ul>
<p>One-Hot 编码常用于表示拥有有限个可能值的字符串或标识符。例如，假设某个指定的植物学数据集记录了 15000 个不同的物种，其中每个物种都用独一无二的字符串标识符来表示。在特征工程过程中，您可能需要将这些字符串标识符编码为 One-Hot 向量，向量的大小为 15000。</p>
<h3 id="独立同分布"><a href="#独立同分布" class="headerlink" title="独立同分布"></a>独立同分布</h3><p>独立就是每次抽样之间是没有关系的,不会相互影响。</p>
<p>同分布，意味着随机变量 $X_1$ 和 $X_2$ 具有相同的分布形状和相同的分布参数，对离散随机变量具有相同的分布律，对连续随机变量具有相同的概率密度函数，有着相同的分布函数，相同的期望、方差。</p>
<p>例如，某个网页的访问者在短时间内的分布可能为独立同分布，即分布在该短时间内没有变化，且一位用户的访问行为通常与另一位用户的访问行为无关。</p>
<h3 id="迭代｜Iteration"><a href="#迭代｜Iteration" class="headerlink" title="迭代｜Iteration"></a>迭代｜Iteration</h3><p>模型的权重在训练期间的一次更新，迭代包含计算参数在单个<strong>批量</strong>数据的梯度损失。</p>
<h2 id="F"><a href="#F" class="headerlink" title="F"></a>F</h2><hr>
<h3 id="泛化｜Generalization"><a href="#泛化｜Generalization" class="headerlink" title="泛化｜Generalization"></a>泛化｜Generalization</h3><p>指的是模型依据训练时采用的数据，针对以前未见过的新数据做出正确预测的能力。</p>
<h3 id="反向传播算法｜Backpropagation"><a href="#反向传播算法｜Backpropagation" class="headerlink" title="反向传播算法｜Backpropagation"></a>反向传播算法｜Backpropagation</h3><p>在神经网络上执行梯度下降法的主要算法。该算法会先按前向传播方式计算（并缓存）每个节点的输出值，然后再按反向传播遍历图的方式计算损失函数值相对于每个参数的偏导数。</p>
<h2 id="G"><a href="#G" class="headerlink" title="G"></a>G</h2><hr>
<h3 id="过拟合｜Overfitting"><a href="#过拟合｜Overfitting" class="headerlink" title="过拟合｜Overfitting"></a>过拟合｜Overfitting</h3><p>创建的模型与训练数据过于匹配，以致于模型无法根据新数据做出正确的预测。</p>
<p>如图，绿线代表过拟合模型，黑线代表正则化模型。虽然绿线完美的匹配训练数据，但太过依赖，并且与黑线相比，对于新的测试数据上具有更高的错误率。</p>
<img style='width:300px' src="https://laugh12321-1258080753.cos.ap-chengdu.myqcloud.com/laugh's%20blog/images/mlg_02.png">

<div style="color: #888; font-size: 10px; text-align: right;"><a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E9%81%8E%E9%81%A9">©️ 图片来源</a></div>

<h2 id="H"><a href="#H" class="headerlink" title="H"></a>H</h2><hr>
<h3 id="混淆矩阵｜Confusion-Matrix"><a href="#混淆矩阵｜Confusion-Matrix" class="headerlink" title="混淆矩阵｜Confusion Matrix"></a>混淆矩阵｜Confusion Matrix</h3><p>一种 NxN 表格，用于总结分类模型的预测成效；即标签和模型预测的分类之间的关联。在混淆矩阵中，一个轴表示模型预测的标签，另一个轴表示实际标签。N 表示类别个数。在二元分类问题中，N=2。例如，下面显示了一个二元分类问题的混淆矩阵示例：</p>
<table>
<thead>
<tr>
<th></th>
<th>肿瘤（预测的标签）</th>
<th>非肿瘤（预测的标签）</th>
</tr>
</thead>
<tbody>
<tr>
<td>肿瘤（实际标签）</td>
<td>18</td>
<td>1</td>
</tr>
<tr>
<td>非肿瘤（实际标签）</td>
<td>6</td>
<td>452</td>
</tr>
</tbody>
</table>

<p>上面的混淆矩阵显示，在 19 个实际有肿瘤的样本中，该模型正确地将 18 个归类为有肿瘤（18 个真正例），错误地将 1 个归类为没有肿瘤（1 个假负例）。同样，在 458 个实际没有肿瘤的样本中，模型归类正确的有 452 个（452 个真负例），归类错误的有 6 个（6 个假正例）。</p>
<p>多类别分类问题的混淆矩阵有助于确定出错模式。例如，某个混淆矩阵可以揭示，某个经过训练以识别手写数字的模型往往会将 4 错误地预测为 9，将 7 错误地预测为 1。混淆矩阵包含计算各种效果指标（包括精确率和召回率）所需的充足信息。</p>
<h2 id="J"><a href="#J" class="headerlink" title="J"></a>J</h2><hr>
<h3 id="集成学习｜Ensemble"><a href="#集成学习｜Ensemble" class="headerlink" title="集成学习｜Ensemble"></a>集成学习｜Ensemble</h3><p>多个<strong>模型</strong>的预测结果的并集。</p>
<p>通俗来讲，集成学习把大大小小的多种算法融合在一起，共同协作来解决一个问题。集成学习可以用于分类问题集成，回归问题集成，特征选取集成，异常点检测集成等。</p>
<p>你可以通过以下一项或多项来创建集成学习：</p>
<ul>
<li>不同的初始化</li>
<li>不同的超参数</li>
<li>不同的整体结构</li>
</ul>
<h3 id="决策边界｜Decision-Boundary"><a href="#决策边界｜Decision-Boundary" class="headerlink" title="决策边界｜Decision Boundary"></a>决策边界｜Decision Boundary</h3><p>在二元分类或多类别分类问题中，模型学到的类别之间的分界线。例如，在以下表示某个二元分类问题的图片中，决策边界是橙色类别和蓝色类别之间的分界线：</p>
<p><img src="https://laugh12321-1258080753.cos.ap-chengdu.myqcloud.com/laugh's%20blog/images/mlg_03.png"></p>
<h3 id="精确率｜Precision"><a href="#精确率｜Precision" class="headerlink" title="精确率｜Precision"></a>精确率｜Precision</h3><p>一种分类模型指标。精确率指模型正确预测正类别的频率。</p>
<p>$$<br>召回率  =   \frac { 真正例数 }  { 真正例数 + 假负例数 }<br>$$</p>
<h3 id="交叉熵｜Cross-Entropy"><a href="#交叉熵｜Cross-Entropy" class="headerlink" title="交叉熵｜Cross-Entropy"></a>交叉熵｜Cross-Entropy</h3><p><strong>对数损失函数</strong>向<strong>多类别分类问题</strong>进行的一种泛化。交叉熵可以量化两种概率分布之间的差异。</p>
<p>$$<br>H(p,q) = \sum_{i=1}^{n} p(x) \cdot log(\frac{1}{q(x)})<br>$$</p>
<h3 id="激活函数｜Activation-Function"><a href="#激活函数｜Activation-Function" class="headerlink" title="激活函数｜Activation Function"></a>激活函数｜Activation Function</h3><p>一种函数（例如 ReLU 或 S 型函数），用于对上一层的所有输入求加权和，然后生成一个输出值（通常为非线性值），并将其传递给下一层。</p>
<h3 id="结构风险最小化｜Structural-Risk-Minimization"><a href="#结构风险最小化｜Structural-Risk-Minimization" class="headerlink" title="结构风险最小化｜Structural Risk Minimization"></a>结构风险最小化｜Structural Risk Minimization</h3><p>一种算法，用于平衡以下两个目标：</p>
<ul>
<li>期望构建最具预测性的模型（例如损失最低）。</li>
<li>期望使模型尽可能简单（例如强大的正则化）。</li>
</ul>
<p>例如，旨在将基于训练集的损失和正则化降至最低的模型函数就是一种结构风险最小化算法。</p>
<h2 id="L"><a href="#L" class="headerlink" title="L"></a>L</h2><hr>
<h3 id="离群点｜Outlier"><a href="#离群点｜Outlier" class="headerlink" title="离群点｜Outlier"></a>离群点｜Outlier</h3><p>与大多数其他值差别很大的值。在机器学习中，下列所有值都是离群值。</p>
<ul>
<li>绝对值很高的权重。</li>
<li>与实际值相差很大的预测值。</li>
<li>值比平均值高大约 3 个标准偏差的输入数据。</li>
</ul>
<p>离群值常常会导致模型训练出现问题。</p>
<h3 id="类别｜Class"><a href="#类别｜Class" class="headerlink" title="类别｜Class"></a>类别｜Class</h3><p>为标签枚举的一组目标值中的一个。例如，在检测垃圾邮件的二元分类模型中，两种类别分别是「垃圾邮件」和「非垃圾邮件」。在识别狗品种的多类别分类模型中，类别可以是「贵宾犬」、「小猎犬」、「哈巴犬」等。</p>
<h3 id="离散特征｜Discrete-Feature"><a href="#离散特征｜Discrete-Feature" class="headerlink" title="离散特征｜Discrete Feature"></a>离散特征｜Discrete Feature</h3><p>一种特征，包含有限个可能值。例如，某个值只能是「动物」、「蔬菜」或「矿物」的特征便是一个离散特征（或分类特征）。与连续特征相对。</p>
<h2 id="M"><a href="#M" class="headerlink" title="M"></a>M</h2><hr>
<h3 id="密集层｜Dense-Layer"><a href="#密集层｜Dense-Layer" class="headerlink" title="密集层｜Dense Layer"></a>密集层｜Dense Layer</h3><p>是全连接层的同义词。</p>
<h2 id="P"><a href="#P" class="headerlink" title="P"></a>P</h2><hr>
<h3 id="批次｜Batch"><a href="#批次｜Batch" class="headerlink" title="批次｜Batch"></a>批次｜Batch</h3><p>模型训练的一次迭代（即一次梯度更新）中使用样本簇。</p>
<h3 id="偏差｜Bias"><a href="#偏差｜Bias" class="headerlink" title="偏差｜Bias"></a>偏差｜Bias</h3><p>距离原点的截距或偏移。偏差（也称为偏差项）在机器学习模型中以 $b$ 或 $w_0$ 表示。例如，在下面的公式中，偏差为 $b$：</p>
<p>$$y’ = b + w_1x_1 + w_2x_2 + … w_nx_n$$</p>
<p>请勿与「预测偏差」混淆。</p>
<h3 id="批次规模｜Batch-Size"><a href="#批次规模｜Batch-Size" class="headerlink" title="批次规模｜Batch Size"></a>批次规模｜Batch Size</h3><p>模型迭代一次，使用的样本集的大小。</p>
<p>例如训练集有 <code>6400</code> 个样本，<code>batch_size=128</code>，那么训练完整个样本集需要 <code>50</code> 次迭代。Batch Size 的大小一般设置为 <code>16</code> 及 <code>16</code> 的倍数。</p>
<h2 id="R"><a href="#R" class="headerlink" title="R"></a>R</h2><hr>
<h3 id="ROC-曲线下面积"><a href="#ROC-曲线下面积" class="headerlink" title="ROC 曲线下面积"></a>ROC 曲线下面积</h3><p>一种会考虑所有可能分类阀值的评价指标。</p>
<p>ROC 曲线下面积的数值意义为：对于随机选择的<strong>正类别样本</strong>确实为正类别，以及随机选择的<strong>负类样本</strong>为正类别，<strong>分类器</strong>更确信前者的概率。</p>
<h2 id="S"><a href="#S" class="headerlink" title="S"></a>S</h2><hr>
<h3 id="输入层｜Input-Layer"><a href="#输入层｜Input-Layer" class="headerlink" title="输入层｜Input Layer"></a>输入层｜Input Layer</h3><p>神经网络中的第一层（接受输入数据的层）</p>
<h3 id="输出层｜Output-Layer"><a href="#输出层｜Output-Layer" class="headerlink" title="输出层｜Output Layer"></a>输出层｜Output Layer</h3><p>神经网络最后一层。</p>
<h3 id="损失｜Loss"><a href="#损失｜Loss" class="headerlink" title="损失｜Loss"></a>损失｜Loss</h3><p>一种衡量指标，用于衡量模型的预测偏离其标签的程度。或者更悲观地说是衡量模型有多差。要确定此值，模型必须定义损失函数。例如，线性回归模型通常将均方误差用于损失函数，而逻辑回归模型则使用对数损失函数。</p>
<h3 id="收敛｜Convergence"><a href="#收敛｜Convergence" class="headerlink" title="收敛｜Convergence"></a>收敛｜Convergence</h3><p>通俗来说，收敛通常是指在训练期间达到的一种状态，即经过一定次数的迭代之后，训练损失和验证损失在每次迭代中的变化都非常小或根本没有变化。也就是说，如果采用当前数据进行额外的训练将无法改进模型，模型即达到收敛状态。在深度学习中，损失值有时会在最终下降之前的多次迭代中保持不变或几乎保持不变，暂时形成收敛的假象。</p>
<h3 id="缩放｜Scaling"><a href="#缩放｜Scaling" class="headerlink" title="缩放｜Scaling"></a>缩放｜Scaling</h3><p>特征工程中的一种常用做法，是对某个特征的值区间进行调整，使之与数据集中其他特征的值区间一致。例如，假设您希望数据集中所有浮点特征的值都位于 0 到 1 区间内，如果某个特征的值位于 0 到 500 区间内，您就可以通过将每个值除以 500 来缩放该特征。</p>
<h3 id="随机梯度下降法｜SGD"><a href="#随机梯度下降法｜SGD" class="headerlink" title="随机梯度下降法｜SGD"></a>随机梯度下降法｜SGD</h3><p>SGD 依赖于从数据集中随机均匀选择的单个样本来计算每步的梯度估算值。</p>
<h3 id="Softmax-函数"><a href="#Softmax-函数" class="headerlink" title="Softmax 函数"></a>Softmax 函数</h3><p>一种函数，可提供多类别分类模型中每个可能类别的概率。这些概率的总和正好为 <code>1.0</code>。例如，softmax 可能会得出某个图像是狗、猫和马的概率分别是 <code>0.9</code>、<code>0.08</code> 和 <code>0.02</code>。（也称为完整 softmax。）</p>
<h2 id="T"><a href="#T" class="headerlink" title="T"></a>T</h2><hr>
<h3 id="推断｜Inference"><a href="#推断｜Inference" class="headerlink" title="推断｜Inference"></a>推断｜Inference</h3><p>在机器学习中，推断通常指以下过程：通过将训练过的模型应用于无标签样本来做出预测。在统计学中，推断是指在某些观测数据条件下拟合分布参数的过程。</p>
<h3 id="梯度｜Gradient"><a href="#梯度｜Gradient" class="headerlink" title="梯度｜Gradient"></a>梯度｜Gradient</h3><p>偏导数相对于所有自变量的向量。在机器学习中，梯度是模型函数偏导数的向量。</p>
<h3 id="梯度下降法｜Gradient-Descent"><a href="#梯度下降法｜Gradient-Descent" class="headerlink" title="梯度下降法｜Gradient Descent"></a>梯度下降法｜Gradient Descent</h3><p>一种通过计算并且减小梯度将损失降至最低的技术，它以训练数据为条件，来计算损失相对于模型参数的梯度。通俗来说，梯度下降法以迭代方式调整参数，逐渐找到权重和偏差的最佳组合，从而将损失降至最低。</p>
<h3 id="特征｜Feature"><a href="#特征｜Feature" class="headerlink" title="特征｜Feature"></a>特征｜Feature</h3><p>在进行预测时使用的输入变量。</p>
<h3 id="特征组合｜Feature-Cross"><a href="#特征组合｜Feature-Cross" class="headerlink" title="特征组合｜Feature Cross"></a>特征组合｜Feature Cross</h3><p>通过将单独的特征进行组合（相乘或求笛卡尔积）而形成的合成特征。特征组合有助于表示非线性关系。</p>
<h3 id="特征工程｜Feature-Engineering"><a href="#特征工程｜Feature-Engineering" class="headerlink" title="特征工程｜Feature Engineering"></a>特征工程｜Feature Engineering</h3><p>指以下过程：确定哪些特征可能在训练模型方面非常有用，然后将日志文件及其他来源的原始数据转换为所需的特征。</p>
<h3 id="凸函数｜Convex-Function"><a href="#凸函数｜Convex-Function" class="headerlink" title="凸函数｜Convex Function"></a>凸函数｜Convex Function</h3><p>一种函数，函数图像以上的区域为凸集。典型凸函数的形状类似于字母 U。例如，以下都是凸函数：</p>
<p><img width='600px' src="https://laugh12321-1258080753.cos.ap-chengdu.myqcloud.com/laugh's%20blog/images/mlg_04.png"></img></p>
<p>严格凸函数只有一个局部最低点，该点也是全局最低点。经典的 U 形函数都是严格凸函数。不过，有些凸函数（例如直线）则不是这样。</p>
<p>很多常见的损失函数（包括下列函数）都是凸函数：</p>
<ul>
<li>L2 损失函数</li>
<li>对数损失函数</li>
<li>L1 正则化</li>
<li>L2 正则化</li>
</ul>
<p>梯度下降法的很多变体都一定能找到一个接近严格凸函数最小值的点。同样，随机梯度下降法的很多变体都有很高的可能性能够找到接近严格凸函数最小值的点（但并非一定能找到）。</p>
<p>两个凸函数的和（例如 L2 损失函数 + L1 正则化）也是凸函数。</p>
<p>深度模型绝不会是凸函数。值得注意的是，专门针对凸优化设计的算法往往总能在深度网络上找到非常好的解决方案，虽然这些解决方案并不一定对应于全局最小值。</p>
<h3 id="凸优化｜Convex-Optimization"><a href="#凸优化｜Convex-Optimization" class="headerlink" title="凸优化｜Convex Optimization"></a>凸优化｜Convex Optimization</h3><p>使用数学方法（例如梯度下降法）寻找凸函数最小值的过程。机器学习方面的大量研究都是专注于如何通过公式将各种问题表示成凸优化问题，以及如何更高效地解决这些问题。</p>
<h2 id="X"><a href="#X" class="headerlink" title="X"></a>X</h2><hr>
<h3 id="学习率｜Learning-Rate"><a href="#学习率｜Learning-Rate" class="headerlink" title="学习率｜Learning Rate"></a>学习率｜Learning Rate</h3><p>在训练模型时用于梯度下降的一个变量。在每次迭代期间，梯度下降法都会将学习速率与梯度相乘。得出的乘积称为梯度步长。</p>
<p>学习速率是一个重要的超参数。</p>
<h3 id="稀疏特征｜Sparse-Feature"><a href="#稀疏特征｜Sparse-Feature" class="headerlink" title="稀疏特征｜Sparse Feature"></a>稀疏特征｜Sparse Feature</h3><p>一种特征向量，其中的大多数值都为 0 或为空。例如，某个向量包含一个为 1 的值和一百万个为 0 的值，则该向量就属于稀疏向量。再举一个例子，搜索查询中的单词也可能属于稀疏特征 - 在某种指定语言中有很多可能的单词，但在某个指定的查询中仅包含其中几个。</p>
<p>与密集特征相对。</p>
<h3 id="协同过滤｜Collabroative-Filtering"><a href="#协同过滤｜Collabroative-Filtering" class="headerlink" title="协同过滤｜Collabroative Filtering"></a>协同过滤｜Collabroative Filtering</h3><p>根据很多其他用户的兴趣来预测某位用户的兴趣。协同过滤通常用在推荐系统中。</p>
<h2 id="Y"><a href="#Y" class="headerlink" title="Y"></a>Y</h2><hr>
<h3 id="预训练模型"><a href="#预训练模型" class="headerlink" title="预训练模型"></a>预训练模型</h3><p>已经过训练的模型或模型组件（例如嵌套）。有时，您需要将预训练的嵌套馈送到神经网络。在其他时候，您的模型将自行训练嵌套，而不依赖于预训练的嵌套。</p>
<h2 id="Z"><a href="#Z" class="headerlink" title="Z"></a>Z</h2><hr>
<h3 id="准确率｜Accuracy"><a href="#准确率｜Accuracy" class="headerlink" title="准确率｜Accuracy"></a>准确率｜Accuracy</h3><p>分类模型的正确预测所占的比例。在多类别分类中，准确率的定义如下：</p>
<p>$$ 准确率  =   \frac { 正确预测数 }  { 样本总数 } $$</p>
<p>在二元分类中，准确率的定义如下：</p>
<p>$$ 准确率  =   \frac { 真正例数 + 真负例数 }  { 样本总数 } $$</p>
<h3 id="真负例"><a href="#真负例" class="headerlink" title="真负例"></a>真负例</h3><p>被模型正确地预测为负类别的样本。例如，模型推断出某封电子邮件不是垃圾邮件，而该电子邮件确实不是垃圾邮件。</p>
<h3 id="真正例"><a href="#真正例" class="headerlink" title="真正例"></a>真正例</h3><p>被模型正确地预测为正类别的样本。例如，模型推断出某封电子邮件是垃圾邮件，而该电子邮件确实是垃圾邮件。</p>
<h3 id="召回率"><a href="#召回率" class="headerlink" title="召回率"></a>召回率</h3><p>一种分类模型指标，用于回答以下问题：在所有可能的正类别标签中，模型正确地识别出了多少个？即：</p>
<p>$$ 召回率  =   \frac { 真正例数 }  { 真正例数  + 假正例数} $$</p>
<h3 id="张量｜Tensor"><a href="#张量｜Tensor" class="headerlink" title="张量｜Tensor"></a>张量｜Tensor</h3><p>TensorFlow 程序中的主要数据结构。张量是 N 维（其中 N 可能非常大）数据结构，最常见的是标量、向量或矩阵。张量的元素可以包含整数值、浮点值或字符串值。</p>
<p><img width='600px' src="https://laugh12321-1258080753.cos.ap-chengdu.myqcloud.com/laugh's%20blog/images/mlg_05.png"></img></p>
<h3 id="迁移学习｜Transfer-Learning"><a href="#迁移学习｜Transfer-Learning" class="headerlink" title="迁移学习｜Transfer Learning"></a>迁移学习｜Transfer Learning</h3><p>将信息从一个机器学习任务转移到另一个机器学习任务。例如，在多任务学习中，一个模型可以完成多项任务，例如针对不同任务具有不同输出节点的深度模型。迁移学习可能涉及将知识从较简单任务的解决方案转移到较复杂的任务，或者将知识从数据较多的任务转移到数据较少的任务。</p>
<p>大多数机器学习系统都只能完成一项任务。迁移学习是迈向人工智能的一小步；在人工智能中，单个程序可以完成多项任务。</p>
<h3 id="L1-正则化｜L1-Regularization"><a href="#L1-正则化｜L1-Regularization" class="headerlink" title="L1 正则化｜L1 Regularization"></a>L1 正则化｜L1 Regularization</h3><p>一种正则化，根据权重的绝对值的总和来惩罚权重。在依赖稀疏特征的模型中，L1 正则化有助于使不相关或几乎不相关的特征的权重正好为 0，从而将这些特征从模型中移除。与 L2 正则化相对。</p>
<h3 id="L2-正则化｜L2-Regularization"><a href="#L2-正则化｜L2-Regularization" class="headerlink" title="L2 正则化｜L2 Regularization"></a>L2 正则化｜L2 Regularization</h3><p>一种正则化，根据权重的平方和来惩罚权重。L2 正则化有助于使离群值（具有较大正值或较小负值）权重接近于 0，但又不正好为 0。（与 L1 正则化相对。）在线性模型中，L2 正则化始终可以改进泛化。</p>
<h3 id="周期｜Epoch"><a href="#周期｜Epoch" class="headerlink" title="周期｜Epoch"></a>周期｜Epoch</h3><p>在训练时，整个数据集的一次完整遍历，以便不漏掉任何一个样本。因此，一个周期表示（N/批次规模）次训练迭代，其中 N 是样本总数。</p>
<hr>
<div style="color: #999;font-size: 12px;font-style: italic;">©️ 部分内容参考自 [Machine Learning Glossary](https://developers.google.com/machine-learning/glossary/)</div></div><div class="article-licensing box"><div class="licensing-title"><p>机器学习术语表</p><p><a href="http://www.laugh12321.cn/blog/2018/11/13/machine_learning_glossary/">http://www.laugh12321.cn/blog/2018/11/13/machine_learning_glossary/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>Laugh</p></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2018-11-13</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2020-10-23</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icon" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a><a class="" rel="noopener" target="_blank" title="CC BY-NC-SA 4.0" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/blog/tags/Machine-Learning/">Machine Learning</a></div><div class="sharethis-inline-share-buttons"></div><script src="https://platform-api.sharethis.com/js/sharethis.js#property=5f902f1aa809f500123872bf&amp;product=inline-share-buttons" defer></script></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">喜欢这篇文章？打赏一下作者吧</h3><div class="buttons is-centered"><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>支付宝</span><span class="qrcode"><img src="https://laugh12321-1258080753.cos.ap-chengdu.myqcloud.com/laugh&#039;s%20blog/images/reward/alipay-reward-image.jpg" alt="支付宝"></span></a><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>微信</span><span class="qrcode"><img src="https://laugh12321-1258080753.cos.ap-chengdu.myqcloud.com/laugh&#039;s%20blog/images/reward/wechat-reward-image.jpg" alt="微信"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/blog/2018/11/24/deep_learning_environment_building_guide/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">深度学习环境搭建指南</span></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">评论</h3><div id="comment-container"></div><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/gitalk/1.6.2/gitalk.css"><script src="https://cdnjs.loli.net/ajax/libs/gitalk/1.6.2/gitalk.min.js"></script><script>var gitalk = new Gitalk({
            id: "ca832eaf10b460d8761bb41eaef2e307",
            repo: "blog",
            owner: "laugh12321",
            clientID: "f831b7db637971edc8c9",
            clientSecret: "9767a6cb27b89b67e2875e8915671499b75a6436",
            admin: ["laugh12321"],
            createIssueManually: true,
            distractionFreeMode: false,
            perPage: 20,
            pagerDirection: "last",
            
            
            enableHotKey: true,
            language: "zh-CN",
        })
        gitalk.render('comment-container')</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1 is-sticky"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="https://avatars0.githubusercontent.com/u/38065710?s=400&amp;u=80ee4d360562451484188e6f1677fa442720891b&amp;v=4" alt="Laugh"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Laugh</p><p class="is-size-6 is-block">The life I want, there is no shortcut.</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Northern Hemisphere</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/blog/archives"><p class="title">26</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/blog/categories"><p class="title">29</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/blog/tags"><p class="title">50</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/laugh12321" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com/laugh12321"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="BiliBili" href="https://space.bilibili.com/86034462"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Weibo" href="https://weibo.com/laugh12321"><i class="fab fa-weibo"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Steam" href="https://steamcommunity.com/id/laugh12321/"><i class="fab fa-steam"></i></a></div></div></div><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">目录</h3><ul class="menu-list"><li><a class="level is-mobile" href="#C"><span class="level-left"><span class="level-item">1</span><span class="level-item">C</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#超参数｜Hyperparameter"><span class="level-left"><span class="level-item">1.1</span><span class="level-item">超参数｜Hyperparameter</span></span></a></li><li><a class="level is-mobile" href="#超平面｜Hyperplane"><span class="level-left"><span class="level-item">1.2</span><span class="level-item">超平面｜Hyperplane</span></span></a></li><li><a class="level is-mobile" href="#参数｜Parameter"><span class="level-left"><span class="level-item">1.3</span><span class="level-item">参数｜Parameter</span></span></a></li><li><a class="level is-mobile" href="#测试集｜Test-Set"><span class="level-left"><span class="level-item">1.4</span><span class="level-item">测试集｜Test Set</span></span></a></li></ul></li><li><a class="level is-mobile" href="#D"><span class="level-left"><span class="level-item">2</span><span class="level-item">D</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#独热编码｜One-Hot-Encoding"><span class="level-left"><span class="level-item">2.1</span><span class="level-item">独热编码｜One-Hot Encoding</span></span></a></li><li><a class="level is-mobile" href="#独立同分布"><span class="level-left"><span class="level-item">2.2</span><span class="level-item">独立同分布</span></span></a></li><li><a class="level is-mobile" href="#迭代｜Iteration"><span class="level-left"><span class="level-item">2.3</span><span class="level-item">迭代｜Iteration</span></span></a></li></ul></li><li><a class="level is-mobile" href="#F"><span class="level-left"><span class="level-item">3</span><span class="level-item">F</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#泛化｜Generalization"><span class="level-left"><span class="level-item">3.1</span><span class="level-item">泛化｜Generalization</span></span></a></li><li><a class="level is-mobile" href="#反向传播算法｜Backpropagation"><span class="level-left"><span class="level-item">3.2</span><span class="level-item">反向传播算法｜Backpropagation</span></span></a></li></ul></li><li><a class="level is-mobile" href="#G"><span class="level-left"><span class="level-item">4</span><span class="level-item">G</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#过拟合｜Overfitting"><span class="level-left"><span class="level-item">4.1</span><span class="level-item">过拟合｜Overfitting</span></span></a></li></ul></li><li><a class="level is-mobile" href="#H"><span class="level-left"><span class="level-item">5</span><span class="level-item">H</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#混淆矩阵｜Confusion-Matrix"><span class="level-left"><span class="level-item">5.1</span><span class="level-item">混淆矩阵｜Confusion Matrix</span></span></a></li></ul></li><li><a class="level is-mobile" href="#J"><span class="level-left"><span class="level-item">6</span><span class="level-item">J</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#集成学习｜Ensemble"><span class="level-left"><span class="level-item">6.1</span><span class="level-item">集成学习｜Ensemble</span></span></a></li><li><a class="level is-mobile" href="#决策边界｜Decision-Boundary"><span class="level-left"><span class="level-item">6.2</span><span class="level-item">决策边界｜Decision Boundary</span></span></a></li><li><a class="level is-mobile" href="#精确率｜Precision"><span class="level-left"><span class="level-item">6.3</span><span class="level-item">精确率｜Precision</span></span></a></li><li><a class="level is-mobile" href="#交叉熵｜Cross-Entropy"><span class="level-left"><span class="level-item">6.4</span><span class="level-item">交叉熵｜Cross-Entropy</span></span></a></li><li><a class="level is-mobile" href="#激活函数｜Activation-Function"><span class="level-left"><span class="level-item">6.5</span><span class="level-item">激活函数｜Activation Function</span></span></a></li><li><a class="level is-mobile" href="#结构风险最小化｜Structural-Risk-Minimization"><span class="level-left"><span class="level-item">6.6</span><span class="level-item">结构风险最小化｜Structural Risk Minimization</span></span></a></li></ul></li><li><a class="level is-mobile" href="#L"><span class="level-left"><span class="level-item">7</span><span class="level-item">L</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#离群点｜Outlier"><span class="level-left"><span class="level-item">7.1</span><span class="level-item">离群点｜Outlier</span></span></a></li><li><a class="level is-mobile" href="#类别｜Class"><span class="level-left"><span class="level-item">7.2</span><span class="level-item">类别｜Class</span></span></a></li><li><a class="level is-mobile" href="#离散特征｜Discrete-Feature"><span class="level-left"><span class="level-item">7.3</span><span class="level-item">离散特征｜Discrete Feature</span></span></a></li></ul></li><li><a class="level is-mobile" href="#M"><span class="level-left"><span class="level-item">8</span><span class="level-item">M</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#密集层｜Dense-Layer"><span class="level-left"><span class="level-item">8.1</span><span class="level-item">密集层｜Dense Layer</span></span></a></li></ul></li><li><a class="level is-mobile" href="#P"><span class="level-left"><span class="level-item">9</span><span class="level-item">P</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#批次｜Batch"><span class="level-left"><span class="level-item">9.1</span><span class="level-item">批次｜Batch</span></span></a></li><li><a class="level is-mobile" href="#偏差｜Bias"><span class="level-left"><span class="level-item">9.2</span><span class="level-item">偏差｜Bias</span></span></a></li><li><a class="level is-mobile" href="#批次规模｜Batch-Size"><span class="level-left"><span class="level-item">9.3</span><span class="level-item">批次规模｜Batch Size</span></span></a></li></ul></li><li><a class="level is-mobile" href="#R"><span class="level-left"><span class="level-item">10</span><span class="level-item">R</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#ROC-曲线下面积"><span class="level-left"><span class="level-item">10.1</span><span class="level-item">ROC 曲线下面积</span></span></a></li></ul></li><li><a class="level is-mobile" href="#S"><span class="level-left"><span class="level-item">11</span><span class="level-item">S</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#输入层｜Input-Layer"><span class="level-left"><span class="level-item">11.1</span><span class="level-item">输入层｜Input Layer</span></span></a></li><li><a class="level is-mobile" href="#输出层｜Output-Layer"><span class="level-left"><span class="level-item">11.2</span><span class="level-item">输出层｜Output Layer</span></span></a></li><li><a class="level is-mobile" href="#损失｜Loss"><span class="level-left"><span class="level-item">11.3</span><span class="level-item">损失｜Loss</span></span></a></li><li><a class="level is-mobile" href="#收敛｜Convergence"><span class="level-left"><span class="level-item">11.4</span><span class="level-item">收敛｜Convergence</span></span></a></li><li><a class="level is-mobile" href="#缩放｜Scaling"><span class="level-left"><span class="level-item">11.5</span><span class="level-item">缩放｜Scaling</span></span></a></li><li><a class="level is-mobile" href="#随机梯度下降法｜SGD"><span class="level-left"><span class="level-item">11.6</span><span class="level-item">随机梯度下降法｜SGD</span></span></a></li><li><a class="level is-mobile" href="#Softmax-函数"><span class="level-left"><span class="level-item">11.7</span><span class="level-item">Softmax 函数</span></span></a></li></ul></li><li><a class="level is-mobile" href="#T"><span class="level-left"><span class="level-item">12</span><span class="level-item">T</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#推断｜Inference"><span class="level-left"><span class="level-item">12.1</span><span class="level-item">推断｜Inference</span></span></a></li><li><a class="level is-mobile" href="#梯度｜Gradient"><span class="level-left"><span class="level-item">12.2</span><span class="level-item">梯度｜Gradient</span></span></a></li><li><a class="level is-mobile" href="#梯度下降法｜Gradient-Descent"><span class="level-left"><span class="level-item">12.3</span><span class="level-item">梯度下降法｜Gradient Descent</span></span></a></li><li><a class="level is-mobile" href="#特征｜Feature"><span class="level-left"><span class="level-item">12.4</span><span class="level-item">特征｜Feature</span></span></a></li><li><a class="level is-mobile" href="#特征组合｜Feature-Cross"><span class="level-left"><span class="level-item">12.5</span><span class="level-item">特征组合｜Feature Cross</span></span></a></li><li><a class="level is-mobile" href="#特征工程｜Feature-Engineering"><span class="level-left"><span class="level-item">12.6</span><span class="level-item">特征工程｜Feature Engineering</span></span></a></li><li><a class="level is-mobile" href="#凸函数｜Convex-Function"><span class="level-left"><span class="level-item">12.7</span><span class="level-item">凸函数｜Convex Function</span></span></a></li><li><a class="level is-mobile" href="#凸优化｜Convex-Optimization"><span class="level-left"><span class="level-item">12.8</span><span class="level-item">凸优化｜Convex Optimization</span></span></a></li></ul></li><li><a class="level is-mobile" href="#X"><span class="level-left"><span class="level-item">13</span><span class="level-item">X</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#学习率｜Learning-Rate"><span class="level-left"><span class="level-item">13.1</span><span class="level-item">学习率｜Learning Rate</span></span></a></li><li><a class="level is-mobile" href="#稀疏特征｜Sparse-Feature"><span class="level-left"><span class="level-item">13.2</span><span class="level-item">稀疏特征｜Sparse Feature</span></span></a></li><li><a class="level is-mobile" href="#协同过滤｜Collabroative-Filtering"><span class="level-left"><span class="level-item">13.3</span><span class="level-item">协同过滤｜Collabroative Filtering</span></span></a></li></ul></li><li><a class="level is-mobile" href="#Y"><span class="level-left"><span class="level-item">14</span><span class="level-item">Y</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#预训练模型"><span class="level-left"><span class="level-item">14.1</span><span class="level-item">预训练模型</span></span></a></li></ul></li><li><a class="level is-mobile" href="#Z"><span class="level-left"><span class="level-item">15</span><span class="level-item">Z</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#准确率｜Accuracy"><span class="level-left"><span class="level-item">15.1</span><span class="level-item">准确率｜Accuracy</span></span></a></li><li><a class="level is-mobile" href="#真负例"><span class="level-left"><span class="level-item">15.2</span><span class="level-item">真负例</span></span></a></li><li><a class="level is-mobile" href="#真正例"><span class="level-left"><span class="level-item">15.3</span><span class="level-item">真正例</span></span></a></li><li><a class="level is-mobile" href="#召回率"><span class="level-left"><span class="level-item">15.4</span><span class="level-item">召回率</span></span></a></li><li><a class="level is-mobile" href="#张量｜Tensor"><span class="level-left"><span class="level-item">15.5</span><span class="level-item">张量｜Tensor</span></span></a></li><li><a class="level is-mobile" href="#迁移学习｜Transfer-Learning"><span class="level-left"><span class="level-item">15.6</span><span class="level-item">迁移学习｜Transfer Learning</span></span></a></li><li><a class="level is-mobile" href="#L1-正则化｜L1-Regularization"><span class="level-left"><span class="level-item">15.7</span><span class="level-item">L1 正则化｜L1 Regularization</span></span></a></li><li><a class="level is-mobile" href="#L2-正则化｜L2-Regularization"><span class="level-left"><span class="level-item">15.8</span><span class="level-item">L2 正则化｜L2 Regularization</span></span></a></li><li><a class="level is-mobile" href="#周期｜Epoch"><span class="level-left"><span class="level-item">15.9</span><span class="level-item">周期｜Epoch</span></span></a></li></ul></li></ul></div></div><style>.menu-list > li > a.is-active + .menu-list { display: block; }.menu-list > li > a + .menu-list { display: none; }</style><script src="/blog/js/toc.js" defer></script></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/blog/categories/Ubuntu/"><span class="level-start"><span class="level-item">Ubuntu</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul><li><a class="level is-mobile" href="/blog/categories/Ubuntu/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"><span class="level-start"><span class="level-item">环境配置</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li><li><a class="level is-mobile" href="/blog/categories/%E5%8D%9A%E5%AE%A2/"><span class="level-start"><span class="level-item">博客</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul><li><a class="level is-mobile" href="/blog/categories/%E5%8D%9A%E5%AE%A2/%E4%B8%BB%E9%A2%98%E7%BE%8E%E5%8C%96/"><span class="level-start"><span class="level-item">主题美化</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/blog/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><span class="level-start"><span class="level-item">机器学习</span></span><span class="level-end"><span class="level-item tag">15</span></span></a><ul><li><a class="level is-mobile" href="/blog/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/K-%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95/"><span class="level-start"><span class="level-item">K-近邻算法</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/blog/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"><span class="level-start"><span class="level-item">人工神经网络</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/blog/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%86%B3%E7%AD%96%E6%A0%91/"><span class="level-start"><span class="level-item">决策树</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/blog/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%88%92%E5%88%86%E8%81%9A%E7%B1%BB/"><span class="level-start"><span class="level-item">划分聚类</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul><li><a class="level is-mobile" href="/blog/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%88%92%E5%88%86%E8%81%9A%E7%B1%BB/K-Means/"><span class="level-start"><span class="level-item">K-Means</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li><li><a class="level is-mobile" href="/blog/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%9A%E9%A1%B9%E5%BC%8F%E5%9B%9E%E5%BD%92/"><span class="level-start"><span class="level-item">多项式回归</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/blog/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%B1%82%E6%AC%A1%E8%81%9A%E7%B1%BB/"><span class="level-start"><span class="level-item">层次聚类</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/blog/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%84%9F%E7%9F%A5%E6%9C%BA/"><span class="level-start"><span class="level-item">感知机</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/blog/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%8F%90%E5%8D%87/"><span class="level-start"><span class="level-item">提升</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/blog/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/"><span class="level-start"><span class="level-item">支持向量机</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/blog/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/"><span class="level-start"><span class="level-item">朴素贝叶斯</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/blog/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D/"><span class="level-start"><span class="level-item">梯度下降</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/blog/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"><span class="level-start"><span class="level-item">线性回归</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/blog/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%A3%85%E8%A2%8B/"><span class="level-start"><span class="level-item">装袋</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/blog/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><span class="level-start"><span class="level-item">深度学习</span></span><span class="level-end"><span class="level-item tag">5</span></span></a><ul><li><a class="level is-mobile" href="/blog/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"><span class="level-start"><span class="level-item">推荐系统</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul><li><a class="level is-mobile" href="/blog/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3/"><span class="level-start"><span class="level-item">矩阵分解</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/blog/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/"><span class="level-start"><span class="level-item">论文翻译</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/blog/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"><span class="level-start"><span class="level-item">计算机视觉</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/blog/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"><span class="level-start"><span class="level-item">卷积神经网络</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/blog/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0/"><span class="level-start"><span class="level-item">迁移学习</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/blog/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0/%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB/"><span class="level-start"><span class="level-item">风格迁移</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></li><li><a class="level is-mobile" href="/blog/categories/%E7%AE%97%E6%B3%95/"><span class="level-start"><span class="level-item">算法</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul><li><a class="level is-mobile" href="/blog/categories/%E7%AE%97%E6%B3%95/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/"><span class="level-start"><span class="level-item">排序算法</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">标签</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/blog/tags/Artificial-Neural-Network/"><span class="tag">Artificial Neural Network</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/BGD/"><span class="tag">BGD</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/BPR/"><span class="tag">BPR</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Bagging/"><span class="tag">Bagging</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Blog/"><span class="tag">Blog</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/BoosTing/"><span class="tag">BoosTing</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/CNN/"><span class="tag">CNN</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/CV/"><span class="tag">CV</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Cluster/"><span class="tag">Cluster</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Decision-Tree/"><span class="tag">Decision Tree</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Deep-Learning/"><span class="tag">Deep Learning</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/ECS/"><span class="tag">ECS</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/GD/"><span class="tag">GD</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/GitHub-Pages/"><span class="tag">GitHub Pages</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Hierarchical-Clustering/"><span class="tag">Hierarchical Clustering</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Jekyll/"><span class="tag">Jekyll</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/K-Means/"><span class="tag">K-Means</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/K-Nearest-Neighbors/"><span class="tag">K-Nearest Neighbors</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/KNN/"><span class="tag">KNN</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Kreas/"><span class="tag">Kreas</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Linear-Regression/"><span class="tag">Linear Regression</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/MAE/"><span class="tag">MAE</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/MAPE/"><span class="tag">MAPE</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/MBGD/"><span class="tag">MBGD</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/MF/"><span class="tag">MF</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/MSE/"><span class="tag">MSE</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Machine-Learning/"><span class="tag">Machine Learning</span><span class="tag">15</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/NN/"><span class="tag">NN</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Naive-Bayes/"><span class="tag">Naive Bayes</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Neural-Network/"><span class="tag">Neural Network</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Neural-Style-Transfer/"><span class="tag">Neural Style Transfer</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Next/"><span class="tag">Next</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Polynomial-Regression/"><span class="tag">Polynomial Regression</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/RS/"><span class="tag">RS</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Recommender-System/"><span class="tag">Recommender System</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/SGD/"><span class="tag">SGD</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/SVM/"><span class="tag">SVM</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Seafile/"><span class="tag">Seafile</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Transfer-Learning/"><span class="tag">Transfer Learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Ubuntu/"><span class="tag">Ubuntu</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/VGG19/"><span class="tag">VGG19</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/%E5%86%92%E6%B3%A1%E6%8E%92%E5%BA%8F/"><span class="tag">冒泡排序</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/%E5%9B%BE%E5%83%8F%E5%8E%8B%E7%BC%A9/"><span class="tag">图像压缩</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/"><span class="tag">快速排序</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/"><span class="tag">排序算法</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/%E6%8F%92%E5%85%A5%E6%8E%92%E5%BA%8F/"><span class="tag">插入排序</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/"><span class="tag">服务器</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"><span class="tag">环境配置</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/%E7%AE%97%E6%B3%95/"><span class="tag">算法</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/%E9%80%89%E6%8B%A9%E6%8E%92%E5%BA%8F/"><span class="tag">选择排序</span><span class="tag">1</span></a></div></div></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/blog/">Laugh</a><p class="is-size-7"><span>&copy; 2020 Laugh</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdnjs.loli.net/ajax/libs/jquery/3.3.1/jquery.min.js"></script><script src="https://cdnjs.loli.net/ajax/libs/moment.js/2.22.2/moment-with-locales.min.js"></script><script src="https://cdnjs.loli.net/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" async></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/blog/js/column.js"></script><script src="/blog/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/blog/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdnjs.loli.net/ajax/libs/cookieconsent/3.1.1/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdnjs.loli.net/ajax/libs/lightgallery/1.6.8/js/lightgallery.min.js" defer></script><script src="https://cdnjs.loli.net/ajax/libs/justifiedGallery/3.7.0/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/KaTeX/0.11.1/katex.min.css"><script src="https://cdnjs.loli.net/ajax/libs/KaTeX/0.11.1/katex.min.js" defer></script><script src="https://cdnjs.loli.net/ajax/libs/KaTeX/0.11.1/contrib/auto-render.min.js" defer></script><script src="https://cdnjs.loli.net/ajax/libs/KaTeX/0.11.1/contrib/mhchem.js" defer></script><script>window.addEventListener("load", function() {
            document.querySelectorAll('[role="article"] > .content').forEach(function(element) {
                renderMathInElement(element);
            });
        });</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdnjs.loli.net/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><div id="outdated"><h6>Your browser is out-of-date!</h6><p>Update your browser to view this website correctly.&amp;npsb;<a id="btnUpdateBrowser" target="_blank" rel="noopener" href="http://outdatedbrowser.com/">Update my browser now </a></p><p class="last"><a href="#" id="btnCloseUpdateBrowser" title="Close">×</a></p></div><script src="https://cdnjs.loli.net/ajax/libs/outdated-browser/1.1.5/outdatedbrowser.min.js" defer></script><script>window.addEventListener("load", function () {
            outdatedBrowser({
                bgColor: '#f25648',
                color: '#ffffff',
                lowerThan: 'object-fit' // display on IE11 or below
            });
        });</script><!--!--><!--!--><!--!--><script src="/blog/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/blog/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/blog/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>