<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>机器学习|多项式回归算法详解 - Laugh&#039;s blog</title><link rel="manifest" href="/blog/manifest.json"><meta name="application-name" content="Laugh&#039;s blog"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Laugh&#039;s blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta description="多项式回归介绍在线性回归中，我们通过建立自变量 x 的一次方程来拟合数据。而非线性回归中，则需要建立因变量和自变量之间的非线性关系。从直观上讲，也就是拟合的直线变成了「曲线」。"><meta property="og:type" content="blog"><meta property="og:title" content="机器学习|多项式回归算法详解"><meta property="og:url" content="http://www.laugh12321.cn/blog/2019/01/04/polynomial_regression/"><meta property="og:site_name" content="Laugh&#039;s blog"><meta property="og:description" content="多项式回归介绍在线性回归中，我们通过建立自变量 x 的一次方程来拟合数据。而非线性回归中，则需要建立因变量和自变量之间的非线性关系。从直观上讲，也就是拟合的直线变成了「曲线」。"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://laugh12321-1258080753.cos.ap-chengdu.myqcloud.com/laugh&#039;s%20blog/images/photo/05.jpg"><meta property="article:published_time" content="2019-01-04T00:00:00.000Z"><meta property="article:modified_time" content="2020-10-21T05:59:02.931Z"><meta property="article:author" content="Laugh"><meta property="article:tag" content="Machine Learning"><meta property="article:tag" content="Polynomial Regression"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://laugh12321-1258080753.cos.ap-chengdu.myqcloud.com/laugh&#039;s%20blog/images/photo/05.jpg"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://www.laugh12321.cn/blog/2019/01/04/polynomial_regression/"},"headline":"Laugh's blog","image":["https://laugh12321-1258080753.cos.ap-chengdu.myqcloud.com/laugh's%20blog/images/photo/05.jpg"],"datePublished":"2019-01-04T00:00:00.000Z","dateModified":"2020-10-21T05:59:02.931Z","author":{"@type":"Person","name":"Laugh"},"description":"多项式回归介绍在线性回归中，我们通过建立自变量 x 的一次方程来拟合数据。而非线性回归中，则需要建立因变量和自变量之间的非线性关系。从直观上讲，也就是拟合的直线变成了「曲线」。"}</script><link rel="canonical" href="http://www.laugh12321.cn/blog/2019/01/04/polynomial_regression/"><link rel="icon" href="/blog/img/favicon.svg"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/font-awesome/5.12.0/css/all.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/highlight.js/9.12.0/styles/atom-one-light.min.css"><link rel="stylesheet" href="https://fonts.loli.net/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/blog/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/cookieconsent/3.1.1/cookieconsent.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/lightgallery/1.6.8/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/justifiedGallery/3.7.0/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdnjs.loli.net/ajax/libs/pace/1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.2.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/blog/">Laugh</a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/blog/">首页</a><a class="navbar-item" href="/blog/archives">归档</a><a class="navbar-item" href="/blog/categories">分类</a><a class="navbar-item" href="/blog/tags">标签</a><a class="navbar-item" href="/blog/about">关于</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="GitHub" href="https://github.com/laugh12321"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="目录" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><div class="card-image"><span class="image is-7by3"><img class="fill" src="https://laugh12321-1258080753.cos.ap-chengdu.myqcloud.com/laugh&#039;s%20blog/images/photo/05.jpg" alt="机器学习|多项式回归算法详解"></span></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2019-01-04T00:00:00.000Z" title="2019-01-04T00:00:00.000Z">2019-01-04</time>发表</span><span class="level-item"><time dateTime="2020-10-21T05:59:02.931Z" title="2020-10-21T05:59:02.931Z">2020-10-21</time>更新</span><span class="level-item"><a class="link-muted" href="/blog/categories/Machine-Learning/">Machine Learning</a><span> / </span><a class="link-muted" href="/blog/categories/Machine-Learning/Polynomial-Regression/">Polynomial Regression</a></span><span class="level-item">22 分钟读完 (大约3227个字)</span></div></div><h1 class="title is-3 is-size-4-mobile">机器学习|多项式回归算法详解</h1><div class="content"><h2 id="多项式回归介绍"><a href="#多项式回归介绍" class="headerlink" title="多项式回归介绍"></a>多项式回归介绍</h2><p>在线性回归中，我们通过建立自变量 <code>x</code> 的一次方程来拟合数据。而非线性回归中，则需要建立因变量和自变量之间的非线性关系。从直观上讲，也就是拟合的直线变成了「曲线」。</p>
<a id="more"></a>

<p>如下图所示，是某地区人口数量的变化数据。如果我们使用线性方差去拟合数据，那么就会存在「肉眼可见」的误差。而对于这样的数据，使用一条曲线去拟合则更符合数据的发展趋势。</p>
<p><img src="https://laugh12321-1258080753.cos.ap-chengdu.myqcloud.com/laugh's%20blog/images/polynomial%20regression/1.png" alt="此处输入图片的描述"></p>
<p>对于非线性回归问题而言，最简单也是最常见的方法就是本次实验要讲解的「多项式回归」。多项式是中学时期就会接触到的概念，这里引用 <a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%A4%9A%E9%A0%85%E5%BC%8F">维基百科</a> 的定义如下：</p>
<blockquote>
<p>多项式（Polynomial）是代数学中的基础概念，是由称为未知数的变量和称为系数的常量通过有限次加法、加减法、乘法以及自然数幂次的乘方运算得到的代数表达式。多项式是整式的一种。未知数只有一个的多项式称为一元多项式；例如 $x^2-3x+4$ 就是一个一元多项式。未知数不止一个的多项式称为多元多项式，例如 $x^3-2xyz^2+2yz+1$ 就是一个三元多项式。</p>
</blockquote>
<h2 id="多项式回归基础"><a href="#多项式回归基础" class="headerlink" title="多项式回归基础"></a>多项式回归基础</h2><p>首先，我们通过一组示例数据来认识多项式回归</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加载示例数据</span></span><br><span class="line">x = [<span class="number">4</span>, <span class="number">8</span>, <span class="number">12</span>, <span class="number">25</span>, <span class="number">32</span>, <span class="number">43</span>, <span class="number">58</span>, <span class="number">63</span>, <span class="number">69</span>, <span class="number">79</span>]</span><br><span class="line">y = [<span class="number">20</span>, <span class="number">33</span>, <span class="number">50</span>, <span class="number">56</span>, <span class="number">42</span>, <span class="number">31</span>, <span class="number">33</span>, <span class="number">46</span>, <span class="number">65</span>, <span class="number">75</span>]</span><br></pre></td></tr></table></figure>

<p>示例数据一共有 10 组，分别对应着横坐标和纵坐标。接下来，通过 Matplotlib 绘制数据，查看其变化趋势。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">plt.scatter(x, y)</span><br></pre></td></tr></table></figure>

<p><img src="https://laugh12321-1258080753.cos.ap-chengdu.myqcloud.com/laugh's%20blog/images/polynomial%20regression/2.png"></p>
<h3 id="实现-2-次多项式拟合"><a href="#实现-2-次多项式拟合" class="headerlink" title="实现 2 次多项式拟合"></a>实现 2 次多项式拟合</h3><p>接下来，通过多项式来拟合上面的散点数据。首先，一个标准的一元高阶多项式函数如下所示：</p>
<p>$$<br>y(x, w) = w_0 + w_1x + w_2x^2 +…+w_mx^m = \sum\limits_{j=0}^{m}w_jx^j \tag{1}<br>$$</p>
<p>其中，m 表示多项式的阶数，x^j 表示 x 的 j 次幂，w 则代表该多项式的系数。</p>
<p>当我们使用上面的多项式去拟合散点时，需要确定两个要素，分别是：多项式系数 $w$ 以及多项式阶数 $m$，这也是多项式的两个基本要素。</p>
<p>如果通过手动指定多项式阶数 $m$ 的大小，那么就只需要确定多项式系数 $w$ 的值是多少。例如，这里首先指定 $m=2$，多项式就变成了：<br>$$<br>y(x, w) = w_0 + w_1x + w_2x^2= \sum\limits_{j=0}^{2}w_jx^j \tag{2}<br>$$<br>当我们确定 $w$ 的值的大小时，就回到了前面线性回归中学习到的内容。</p>
<p>首先，我们构造两个函数，分别是用于拟合的多项式函数，以及误差函数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;实现 2 次多项式函数及误差函数</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">func</span>(<span class="params">p, x</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;根据公式，定义 2 次多项式函数</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    w0, w1, w2 = p</span><br><span class="line">    f = w0 + w1*x + w2*x*x</span><br><span class="line">    <span class="keyword">return</span> f</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">err_func</span>(<span class="params">p, x, y</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;残差函数（观测值与拟合值之间的差距）</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    ret = func(p, x) - y</span><br><span class="line">    <span class="keyword">return</span> ret</span><br></pre></td></tr></table></figure>

<p>接下来，使用 NumPy 提供的随机数方法初始化 3 个 $w$ 参数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">p_init = np.random.randn(<span class="number">3</span>) <span class="comment"># 生成 3 个随机数</span></span><br><span class="line"></span><br><span class="line">p_init</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">array([ <span class="number">0.60995017</span>,  <span class="number">1.32614407</span>, <span class="number">-1.22657863</span>])</span><br></pre></td></tr></table></figure>

<p>接下来，就是使用最小二乘法求解最优参数的过程。这里为了方便，我们直接使用 Scipy 提供的最小二乘法类，得到最佳拟合参数。当然，你完全可以按照线性回归实验中最小二乘法公式自行求解参数。不过，实际工作中为了快速实现，往往会使用像 Scipy 这样现成的函数，这里也是为了给大家多介绍一种方法。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;使用 Scipy 提供的最小二乘法函数得到最佳拟合参数</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">from</span> scipy.optimize <span class="keyword">import</span> leastsq</span><br><span class="line"></span><br><span class="line">parameters = leastsq(err_func, p_init, args=(np.array(x), np.array(y)))</span><br><span class="line"></span><br><span class="line">print(<span class="string">&#x27;Fitting Parameters: &#x27;</span>, parameters[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>

<blockquote>
<p>关于 <code>scipy.optimize.leastsq()</code> 的具体使用介绍，可以阅读 <a target="_blank" rel="noopener" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.leastsq.html">官方文档</a>。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Fitting Parameters:  [ <span class="number">3.76893126e+01</span> <span class="number">-2.60474221e-01</span>  <span class="number">8.00078171e-03</span>]</span><br></pre></td></tr></table></figure>

<p>我们这里得到的最佳拟合参数 $w_0$, $w_1$, $w_2$ 依次为 <code>3.76893117e+01</code>, <code>-2.60474147e-01</code> 和 <code>8.00078082e-03</code>。也就是说，我们拟合后的函数（保留两位有效数字）为：</p>
<p>$$<br>y(x) = 37 - 0.26<em>x + 0.0080</em>x^2 \tag{3}<br>$$</p>
<p>然后，我们尝试绘制出拟合后的图像。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;绘制 2 次多项式拟合图像</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="comment"># 绘制拟合图像时需要的临时点</span></span><br><span class="line">x_temp = np.linspace(<span class="number">0</span>, <span class="number">80</span>, <span class="number">10000</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制拟合函数曲线</span></span><br><span class="line">plt.plot(x_temp, func(parameters[<span class="number">0</span>], x_temp), <span class="string">&#x27;r&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制原数据点</span></span><br><span class="line">plt.scatter(x, y)</span><br></pre></td></tr></table></figure>

<p><img src="https://laugh12321-1258080753.cos.ap-chengdu.myqcloud.com/laugh's%20blog/images/polynomial%20regression/3.png"></p>
<h3 id="实现-N-次多项式拟合"><a href="#实现-N-次多项式拟合" class="headerlink" title="实现 N 次多项式拟合"></a>实现 N 次多项式拟合</h3><p>你会发现，上面采用 <code>2</code> 次多项式拟合的结果也不能恰当地反映散点的变化趋势。此时，我们可以尝试 <code>3</code> 次及更高次多项式拟合。接下来的代码中，我们将针对上面 <code>2</code> 次多项式拟合的代码稍作修改，实现一个 <code>N</code> 次多项式拟合的方法。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;实现 n 次多项式拟合</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fit_func</span>(<span class="params">p, x</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;根据公式，定义 n 次多项式函数</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    f = np.poly1d(p)</span><br><span class="line">    <span class="keyword">return</span> f(x)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">err_func</span>(<span class="params">p, x, y</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;残差函数（观测值与拟合值之间的差距）</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    ret = fit_func(p, x) - y</span><br><span class="line">    <span class="keyword">return</span> ret</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">n_poly</span>(<span class="params">n</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;n 次多项式拟合</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    p_init = np.random.randn(n) <span class="comment"># 生成 n 个随机数</span></span><br><span class="line">    parameters = leastsq(err_func, p_init, args=(np.array(x), np.array(y)))</span><br><span class="line">    <span class="keyword">return</span> parameters[<span class="number">0</span>]</span><br></pre></td></tr></table></figure>

<p>可以使用 <code>n=3</code> 验证一下上面的代码是否可用。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">n_poly(<span class="number">3</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">array([ <span class="number">8.00077828e-03</span>, <span class="number">-2.60473932e-01</span>,  <span class="number">3.76893089e+01</span>])</span><br></pre></td></tr></table></figure>

<p>此时得到的参数结果和公式（3）的结果一致，只是顺序有出入。这是因为 NumPy 中的多项式函数 <code>np.poly1d(3)</code> 默认的样式是：</p>
<p>$$<br>y(x) = 0.0080<em>x^2 - 0.26</em>x + 37\tag{4}<br>$$<br>接下来，我们绘制出 <code>4，5，6，7, 8, 9</code> 次多项式的拟合结果。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;绘制出 4，5，6，7, 8, 9 次多项式的拟合图像</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制拟合图像时需要的临时点</span></span><br><span class="line">x_temp = np.linspace(<span class="number">0</span>, <span class="number">80</span>, <span class="number">10000</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制子图</span></span><br><span class="line">fig, axes = plt.subplots(<span class="number">2</span>, <span class="number">3</span>, figsize=(<span class="number">15</span>,<span class="number">10</span>))</span><br><span class="line"></span><br><span class="line">axes[<span class="number">0</span>,<span class="number">0</span>].plot(x_temp, fit_func(n_poly(<span class="number">4</span>), x_temp), <span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">axes[<span class="number">0</span>,<span class="number">0</span>].scatter(x, y)</span><br><span class="line">axes[<span class="number">0</span>,<span class="number">0</span>].set_title(<span class="string">&quot;m = 4&quot;</span>)</span><br><span class="line"></span><br><span class="line">axes[<span class="number">0</span>,<span class="number">1</span>].plot(x_temp, fit_func(n_poly(<span class="number">5</span>), x_temp), <span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">axes[<span class="number">0</span>,<span class="number">1</span>].scatter(x, y)</span><br><span class="line">axes[<span class="number">0</span>,<span class="number">1</span>].set_title(<span class="string">&quot;m = 5&quot;</span>)</span><br><span class="line"></span><br><span class="line">axes[<span class="number">0</span>,<span class="number">2</span>].plot(x_temp, fit_func(n_poly(<span class="number">6</span>), x_temp), <span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">axes[<span class="number">0</span>,<span class="number">2</span>].scatter(x, y)</span><br><span class="line">axes[<span class="number">0</span>,<span class="number">2</span>].set_title(<span class="string">&quot;m = 6&quot;</span>)</span><br><span class="line"></span><br><span class="line">axes[<span class="number">1</span>,<span class="number">0</span>].plot(x_temp, fit_func(n_poly(<span class="number">7</span>), x_temp), <span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">axes[<span class="number">1</span>,<span class="number">0</span>].scatter(x, y)</span><br><span class="line">axes[<span class="number">1</span>,<span class="number">0</span>].set_title(<span class="string">&quot;m = 7&quot;</span>)</span><br><span class="line"></span><br><span class="line">axes[<span class="number">1</span>,<span class="number">1</span>].plot(x_temp, fit_func(n_poly(<span class="number">8</span>), x_temp), <span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">axes[<span class="number">1</span>,<span class="number">1</span>].scatter(x, y)</span><br><span class="line">axes[<span class="number">1</span>,<span class="number">1</span>].set_title(<span class="string">&quot;m = 8&quot;</span>)</span><br><span class="line"></span><br><span class="line">axes[<span class="number">1</span>,<span class="number">2</span>].plot(x_temp, fit_func(n_poly(<span class="number">9</span>), x_temp), <span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">axes[<span class="number">1</span>,<span class="number">2</span>].scatter(x, y)</span><br><span class="line">axes[<span class="number">1</span>,<span class="number">2</span>].set_title(<span class="string">&quot;m = 9&quot;</span>)</span><br></pre></td></tr></table></figure>

<p><img src="https://laugh12321-1258080753.cos.ap-chengdu.myqcloud.com/laugh's%20blog/images/polynomial%20regression/4.png"></p>
<p>从上面的 <code>6</code> 张图可以看出，当 <code>m=4</code>（4 次多项式） 时，图像拟合的效果已经明显优于 <code>m=3</code> 的结果。但是随着 m 次数的增加，当 m=8 时，曲线呈现出明显的震荡，这也就是线性回归实验中所讲到的过拟和（Overfitting）现象。</p>
<h3 id="使用-scikit-learn-进行多项式拟合"><a href="#使用-scikit-learn-进行多项式拟合" class="headerlink" title="使用 scikit-learn 进行多项式拟合"></a>使用 scikit-learn 进行多项式拟合</h3><p>除了像上面我们自己去定义多项式及实现多项式回归拟合过程，也可以使用 <code>scikit-learn</code> 提供的多项式回归方法来完成。这里，我们会用到<code>sklearn.preprocessing.PolynomialFeatures()</code> 这个类。<code>PolynomialFeatures()</code> 主要的作用是产生多项式特征矩阵。<strong>如果你第一次接触这个概念，可能需要仔细理解下面的内容。</strong></p>
<p>对于一个二次多项式而言，我们知道它的标准形式为：$ y(x, w) = w_0 + w_1x + w_2x^2 $。但是，多项式回归却相当于线性回归的特殊形式。例如，我们这里令 $x = x_1$, $x^2 = x_2$ ，那么原方程就转换为：$ y(x, w) = w_0 + w_1<em>x_1 + w_2</em>x_2 $，这也就变成了多元线性回归。这就完成了<strong>一元高次多项式到多元一次多项式之间的转换</strong>。</p>
<p>举例说明，对于自变量向量 $X$ 和因变量 $y$，如果 $X$：</p>
<p>$$<br>\mathbf{X} = \begin{bmatrix}<br>       2    \[0.3em]<br>       -1 \[0.3em]<br>       3<br>     \end{bmatrix} \tag{5a}<br>$$<br>我们可以通过 $ y = w_1 x + w_0$ 线性回归模型进行拟合。同样，如果对于一元二次多项式 $ y(x, w) = w_0 + w_1x + w_2x^2 $，如果能得到由 $x = x_1$, $x^2 = x_2$ 构成的特征矩阵，即：</p>
<p>$$<br>\mathbf{X} = \left [ X, X^2 \right ] = \begin{bmatrix}<br> 2&amp; 4\ -1<br> &amp; 1\ 3<br> &amp; 9<br>\end{bmatrix}<br>\tag{5b}<br>$$<br>那么也就可以通过线性回归进行拟合了。</p>
<p>你可以手动计算上面的结果，但是<strong>当多项式为一元高次或者多元高次时，特征矩阵的表达和计算过程就变得比较复杂了</strong>。例如，下面是二元二次多项式的特征矩阵表达式。</p>
<p>$$<br>\mathbf{X} = \left [ X_{1}, X_{2}, X_{1}^2, X_{1}X_{2}, X_{2}^2 \right ]<br>\tag{5c}<br>$$<br>还好，在 scikit-learn 中，我们可以通过 <code>PolynomialFeatures()</code> 类自动产生多项式特征矩阵，<code>PolynomialFeatures()</code> 类的默认参数及常用参数定义如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sklearn.preprocessing.PolynomialFeatures(degree=<span class="number">2</span>, interaction_only=<span class="literal">False</span>, include_bias=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li><code>degree</code>: 多项式次数，默认为 2 次多项式</li>
<li><code>interaction_only</code>: 默认为 False，如果为 True 则产生相互影响的特征集。</li>
<li><code>include_bias</code>: 默认为 True，包含多项式中的截距项。</li>
</ul>
<p>对应上面的特征向量，我们使用 <code>PolynomialFeatures()</code> 的主要作用是产生 2 次多项式对应的特征矩阵，如下所示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;使用 PolynomialFeatures 自动生成特征矩阵</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> PolynomialFeatures</span><br><span class="line"></span><br><span class="line">X=[<span class="number">2</span>, <span class="number">-1</span>, <span class="number">3</span>]</span><br><span class="line">X_reshape = np.array(X).reshape(<span class="built_in">len</span>(X), <span class="number">1</span>) <span class="comment"># 转换为列向量</span></span><br><span class="line">PolynomialFeatures(degree=<span class="number">2</span>, include_bias=<span class="literal">False</span>).fit_transform(X_reshape)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">array([[ <span class="number">2.</span>,  <span class="number">4.</span>],</span><br><span class="line">       [<span class="number">-1.</span>,  <span class="number">1.</span>],</span><br><span class="line">       [ <span class="number">3.</span>,  <span class="number">9.</span>]])</span><br></pre></td></tr></table></figure>

<p>对于上方单元格中的矩阵，第 1 列为 $X^1$，第 2 列为 $X^2$。我们就可以通过多元线性方程 $ y(x, w) = w_0 + w_1<em>x_1 + w_2</em>x_2 $ 对数据进行拟合。</p>
<blockquote>
<p>注意：本篇文章中，你会看到大量的 <code>reshape</code> 操作，它们的目的都是为了满足某些类传参的数组形状。这些操作在本实验中是必须的，因为数据原始形状（如上面的一维数组）可能无法直接传入某些特定类中。但在实际工作中并不是必须的，因为你手中的原始数据集形状可能支持直接传入。所以，不必为这些 <code>reshape</code> 操作感到疑惑，也不要死记硬背。</p>
</blockquote>
<p>回到 <code>2.1</code> 小节中的示例数据，其自变量应该是 $x$，而因变量是 $y$。如果我们使用 2 次多项式拟合，那么首先使用 <code>PolynomialFeatures()</code> 得到特征矩阵。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;使用 sklearn 得到 2 次多项式回归特征矩阵</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> PolynomialFeatures</span><br><span class="line"></span><br><span class="line">x = np.array(x).reshape(<span class="built_in">len</span>(x), <span class="number">1</span>) <span class="comment"># 转换为列向量</span></span><br><span class="line">y = np.array(y).reshape(<span class="built_in">len</span>(y), <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">poly_features = PolynomialFeatures(degree=<span class="number">2</span>, include_bias=<span class="literal">False</span>)</span><br><span class="line">poly_x = poly_features.fit_transform(x)</span><br><span class="line"></span><br><span class="line">poly_x</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">array([[<span class="number">4.000e+00</span>, <span class="number">1.600e+01</span>],</span><br><span class="line">       [<span class="number">8.000e+00</span>, <span class="number">6.400e+01</span>],</span><br><span class="line">       [<span class="number">1.200e+01</span>, <span class="number">1.440e+02</span>],</span><br><span class="line">       [<span class="number">2.500e+01</span>, <span class="number">6.250e+02</span>],</span><br><span class="line">       [<span class="number">3.200e+01</span>, <span class="number">1.024e+03</span>],</span><br><span class="line">       [<span class="number">4.300e+01</span>, <span class="number">1.849e+03</span>],</span><br><span class="line">       [<span class="number">5.800e+01</span>, <span class="number">3.364e+03</span>],</span><br><span class="line">       [<span class="number">6.300e+01</span>, <span class="number">3.969e+03</span>],</span><br><span class="line">       [<span class="number">6.900e+01</span>, <span class="number">4.761e+03</span>],</span><br><span class="line">       [<span class="number">7.900e+01</span>, <span class="number">6.241e+03</span>]])</span><br></pre></td></tr></table></figure>

<p>可以看到，输出结果正好对应一元二次多项式特征矩阵公式：$\left [ X, X^2 \right ]$</p>
<p>然后，我们使用 scikit-learn 训练线性回归模型。这里将会使用到 <code>LinearRegression()</code> 类，<code>LinearRegression()</code> 类的默认参数及常用参数定义如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sklearn.linear_model.LinearRegression(fit_intercept=<span class="literal">True</span>, normalize=<span class="literal">False</span>, copy_X=<span class="literal">True</span>, n_jobs=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li><code>fit_intercept</code>: 默认为 True，计算截距项。</li>
<li><code>normalize</code>: 默认为 False，不针对数据进行标准化处理。</li>
<li><code>copy_X</code>: 默认为 True，即使用数据的副本进行操作，防止影响原数据。</li>
<li><code>n_jobs</code>: 计算时的作业数量。默认为 1，若为 -1 则使用全部 CPU 参与运算。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;转换为线性回归预测</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义线性回归模型</span></span><br><span class="line">model = LinearRegression()</span><br><span class="line">model.fit(poly_x, y) <span class="comment"># 训练</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 得到模型拟合参数</span></span><br><span class="line">model.intercept_, model.coef_</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(array([<span class="number">2.13162821e-14</span>]), array([[<span class="number">1.00000000e+00</span>, <span class="number">4.35999447e-18</span>]]))</span><br></pre></td></tr></table></figure>

<p>你会发现，这里得到的参数值和公式（3），（4）一致。为了更加直观，这里同样绘制出拟合后的图像。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;绘制拟合图像</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">x_temp = np.array(x_temp).reshape(<span class="built_in">len</span>(x_temp),<span class="number">1</span>)</span><br><span class="line">poly_x_temp = poly_features.fit_transform(x_temp)</span><br><span class="line"></span><br><span class="line">plt.plot(x_temp, model.predict(poly_x_temp), <span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">plt.scatter(x, y)</span><br></pre></td></tr></table></figure>

<p><img src="https://laugh12321-1258080753.cos.ap-chengdu.myqcloud.com/laugh's%20blog/images/polynomial%20regression/5.png"></p>
<p>你会发现，上图似曾相识。它和公式（3）下方的图其实是一致的。</p>
</div><div class="article-licensing box"><div class="licensing-title"><p>机器学习|多项式回归算法详解</p><p><a href="http://www.laugh12321.cn/blog/2019/01/04/polynomial_regression/">http://www.laugh12321.cn/blog/2019/01/04/polynomial_regression/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>Laugh</p></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2019-01-04</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2020-10-21</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icon" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a><a class="" rel="noopener" target="_blank" title="CC BY-NC-SA 4.0" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/blog/tags/Machine-Learning/">Machine Learning</a><a class="link-muted mr-2" rel="tag" href="/blog/tags/Polynomial-Regression/">Polynomial Regression</a></div><div class="notification is-danger">You need to set <code>install_url</code> to use ShareThis. Please set it in <code>_config.yml</code>.</div></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">喜欢这篇文章？打赏一下作者吧</h3><div class="buttons is-centered"><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>支付宝</span><span class="qrcode"><img src="https://laugh12321-1258080753.cos.ap-chengdu.myqcloud.com/laugh&#039;s%20blog/images/reward/alipay-reward-image.jpg" alt="支付宝"></span></a><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>微信</span><span class="qrcode"><img src="https://laugh12321-1258080753.cos.ap-chengdu.myqcloud.com/laugh&#039;s%20blog/images/reward/wechat-reward-image.jpg" alt="微信"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/blog/2019/01/07/k_nearest_neighbors/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">机器学习| K-近邻算法详解</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/blog/2019/01/02/evaluation_index_with_linear_regression/"><span class="level-item">机器学习|线性回归三大评价指标实现『MAE, MSE, MAPE』</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">评论</h3><div class="notification is-danger">You forgot to set the <code>shortname</code> for Disqus. Please set it in <code>_config.yml</code>.</div></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1 is-sticky"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="https://avatars0.githubusercontent.com/u/38065710?s=400&amp;u=80ee4d360562451484188e6f1677fa442720891b&amp;v=4" alt="Laugh"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Laugh</p><p class="is-size-6 is-block">The life I want, there is no shortcut.</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Northern Hemisphere</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/blog/archives"><p class="title">16</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/blog/categories"><p class="title">15</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/blog/tags"><p class="title">22</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/laugh12321" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/laugh12321"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/blog/"><i class="fas fa-rss"></i></a></div></div></div><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">目录</h3><ul class="menu-list"><li><a class="level is-mobile" href="#多项式回归介绍"><span class="level-left"><span class="level-item">1</span><span class="level-item">多项式回归介绍</span></span></a></li><li><a class="level is-mobile" href="#多项式回归基础"><span class="level-left"><span class="level-item">2</span><span class="level-item">多项式回归基础</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#实现-2-次多项式拟合"><span class="level-left"><span class="level-item">2.1</span><span class="level-item">实现 2 次多项式拟合</span></span></a></li><li><a class="level is-mobile" href="#实现-N-次多项式拟合"><span class="level-left"><span class="level-item">2.2</span><span class="level-item">实现 N 次多项式拟合</span></span></a></li><li><a class="level is-mobile" href="#使用-scikit-learn-进行多项式拟合"><span class="level-left"><span class="level-item">2.3</span><span class="level-item">使用 scikit-learn 进行多项式拟合</span></span></a></li></ul></li></ul></div></div><style>.menu-list > li > a.is-active + .menu-list { display: block; }.menu-list > li > a + .menu-list { display: none; }</style><script src="/blog/js/toc.js" defer></script></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/blog/categories/Algorithm/"><span class="level-start"><span class="level-item">Algorithm</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul><li><a class="level is-mobile" href="/blog/categories/Algorithm/Sorting-algorithm/"><span class="level-start"><span class="level-item">Sorting algorithm</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li><li><a class="level is-mobile" href="/blog/categories/Blog/"><span class="level-start"><span class="level-item">Blog</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/blog/categories/Deep-Learning/"><span class="level-start"><span class="level-item">Deep Learning</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/blog/categories/Machine-Learning/"><span class="level-start"><span class="level-item">Machine Learning</span></span><span class="level-end"><span class="level-item tag">9</span></span></a><ul><li><a class="level is-mobile" href="/blog/categories/Machine-Learning/Decision-Tree/"><span class="level-start"><span class="level-item">Decision Tree</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/blog/categories/Machine-Learning/K-Nearest-Neighbors/"><span class="level-start"><span class="level-item">K-Nearest Neighbors</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/blog/categories/Machine-Learning/Linear-Regression/"><span class="level-start"><span class="level-item">Linear Regression</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/blog/categories/Machine-Learning/Naive-Bayes/"><span class="level-start"><span class="level-item">Naive Bayes</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/blog/categories/Machine-Learning/Neural-Network/"><span class="level-start"><span class="level-item">Neural Network</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/blog/categories/Machine-Learning/Polynomial-Regression/"><span class="level-start"><span class="level-item">Polynomial Regression</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/blog/categories/Machine-Learning/Support-Vector-Machine/"><span class="level-start"><span class="level-item">Support Vector Machine</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/blog/categories/Ubuntu/"><span class="level-start"><span class="level-item">Ubuntu</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul><li><a class="level is-mobile" href="/blog/categories/Ubuntu/ECS/"><span class="level-start"><span class="level-item">ECS</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul><li><a class="level is-mobile" href="/blog/categories/Ubuntu/ECS/Seafile/"><span class="level-start"><span class="level-item">Seafile</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">标签</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/blog/tags/Algorithm/"><span class="tag">Algorithm</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Blog/"><span class="tag">Blog</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Decision-Tree/"><span class="tag">Decision Tree</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Deep-Learning/"><span class="tag">Deep Learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/ECS/"><span class="tag">ECS</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/GitHub-Pages/"><span class="tag">GitHub Pages</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Jekyll/"><span class="tag">Jekyll</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/K-Nearest-Neighbors/"><span class="tag">K-Nearest Neighbors</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Linear-Regression/"><span class="tag">Linear Regression</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/MAE/"><span class="tag">MAE</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/MAPE/"><span class="tag">MAPE</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/MSE/"><span class="tag">MSE</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Machine-Learning/"><span class="tag">Machine Learning</span><span class="tag">9</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Naive-Bayes/"><span class="tag">Naive Bayes</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Neural-Network/"><span class="tag">Neural Network</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Next/"><span class="tag">Next</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Polynomial-Regression/"><span class="tag">Polynomial Regression</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Seafile/"><span class="tag">Seafile</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Sorting-algorithm/"><span class="tag">Sorting algorithm</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Support-Vector-Machine/"><span class="tag">Support Vector Machine</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Ubuntu/"><span class="tag">Ubuntu</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/"><span class="tag">服务器</span><span class="tag">2</span></a></div></div></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/blog/">Laugh</a><p class="is-size-7"><span>&copy; 2020 Laugh</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdnjs.loli.net/ajax/libs/jquery/3.3.1/jquery.min.js"></script><script src="https://cdnjs.loli.net/ajax/libs/moment.js/2.22.2/moment-with-locales.min.js"></script><script src="https://cdnjs.loli.net/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" async></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/blog/js/column.js"></script><script src="/blog/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/blog/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdnjs.loli.net/ajax/libs/cookieconsent/3.1.1/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdnjs.loli.net/ajax/libs/lightgallery/1.6.8/js/lightgallery.min.js" defer></script><script src="https://cdnjs.loli.net/ajax/libs/justifiedGallery/3.7.0/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdnjs.loli.net/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/blog/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/blog/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/blog/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>